{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e4b223",
   "metadata": {},
   "source": [
    "### 使用transformer库的pipline进行推理\n",
    "\n",
    "pipline是一个抽象的类，任何模型都可以作为一个pipline实例化的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd6e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 22aad52 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\")\n",
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06852ba1",
   "metadata": {},
   "source": [
    "上边仅指定任务没指定模型，因此pipline针对语音转文字任务选择了默认模型，我们可以在huggingface的模型库里将pipline tags选择为我们想要实现的任务，然后在各类开源模型中选择合适的模型，比如这里我们选择一个0.2B的小模型openai/whisper-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82021044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': '能听见我说话吗?我现在在说中文。Can you hear me?I am speaking English now.'},\n",
       " {'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fattened sauce.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-small\",device=0)\n",
    "results = transcriber([\"my_sound.flac\",\n",
    "             \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ff4fb",
   "metadata": {},
   "source": [
    "这个例子也展示了如何批量输入，输出的结构是列表，列表的每个元素是一个字典\n",
    "\n",
    "在pipline中可以通过device=n的参数来固定调用某一个GPU，也可以通过device_map=\"auto\"的方式使模型自动调度，二者不可同时存在\n",
    "\n",
    "接下来展示一个语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ea015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "LLM = pipeline(model=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
